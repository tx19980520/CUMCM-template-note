{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ty020\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jieba\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "olderr = np.seterr(all='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"D:\\\\杂七杂八课程\\\\CUMCM-template-note\\\\NLP\\\\doubanMoviereview--master\\\\scrapy_data\\\\data_long\\\\三傻大闹宝莱坞.csv\")\n",
    "raw_data = pd.read_csv(f,usecols=['评论内容', '推荐星数'])\n",
    "raw_data\n",
    "raw_labels = raw_data[\"推荐星数\"].tolist()\n",
    "y_labels = []\n",
    "for label in raw_labels:\n",
    "    if label == \"还行\" or label == \"很差\" or label == \"较差\":\n",
    "        y_labels.append(0)\n",
    "    else:\n",
    "        y_labels.append(1)\n",
    "x_comments = raw_data[\"评论内容\"].tolist()\n",
    "doc_vec = []\n",
    "for comment in x_comments:\n",
    "    doc_vec.append(jieba.cut(comment.strip(), cut_all=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(x_comments)]\n",
    "model = Doc2Vec(documents, vector_size=20, min_count=2, epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "#split train and split\n",
    "from sklearn.model_selection import train_test_split\n",
    "comment_vec = []\n",
    "for i in range(len(documents)):\n",
    "    comment_vec.append(np.array(model.docvecs[i]))\n",
    "train_comments, test_comments, train_labels, test_labels = train_test_split(comment_vec, y_labels, test_size=0.33, random_state=42)\n",
    "print(model.docvecs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2418/2418 [==============================] - 1s 252us/step - loss: 1.1292 - acc: 0.9376\n",
      "Epoch 2/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.7849 - acc: 0.9376\n",
      "Epoch 3/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.6685 - acc: 0.9376\n",
      "Epoch 4/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.6176 - acc: 0.9376\n",
      "Epoch 5/400\n",
      "2418/2418 [==============================] - 0s 61us/step - loss: 0.5925 - acc: 0.9376\n",
      "Epoch 6/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5792 - acc: 0.9376\n",
      "Epoch 7/400\n",
      "2418/2418 [==============================] - 0s 64us/step - loss: 0.5709 - acc: 0.9376\n",
      "Epoch 8/400\n",
      "2418/2418 [==============================] - 0s 62us/step - loss: 0.5653 - acc: 0.9376\n",
      "Epoch 9/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5622 - acc: 0.9376\n",
      "Epoch 10/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5590 - acc: 0.9376\n",
      "Epoch 11/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5575 - acc: 0.9376\n",
      "Epoch 12/400\n",
      "2418/2418 [==============================] - 0s 66us/step - loss: 0.5549 - acc: 0.9376\n",
      "Epoch 13/400\n",
      "2418/2418 [==============================] - 0s 63us/step - loss: 0.5547 - acc: 0.9376\n",
      "Epoch 14/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5515 - acc: 0.9376\n",
      "Epoch 15/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5510 - acc: 0.9376\n",
      "Epoch 16/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5499 - acc: 0.9376\n",
      "Epoch 17/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5490 - acc: 0.9376\n",
      "Epoch 18/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5494 - acc: 0.9376\n",
      "Epoch 19/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5472 - acc: 0.9376\n",
      "Epoch 20/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5468 - acc: 0.9376\n",
      "Epoch 21/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5455 - acc: 0.9376\n",
      "Epoch 22/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5461 - acc: 0.9376\n",
      "Epoch 23/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5467 - acc: 0.9376\n",
      "Epoch 24/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5460 - acc: 0.9376\n",
      "Epoch 25/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5476 - acc: 0.9376\n",
      "Epoch 26/400\n",
      "2418/2418 [==============================] - 0s 63us/step - loss: 0.5460 - acc: 0.9376\n",
      "Epoch 27/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5442 - acc: 0.9376\n",
      "Epoch 28/400\n",
      "2418/2418 [==============================] - 0s 65us/step - loss: 0.5449 - acc: 0.9376\n",
      "Epoch 29/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5456 - acc: 0.9376\n",
      "Epoch 30/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5439 - acc: 0.9376\n",
      "Epoch 31/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5454 - acc: 0.9376\n",
      "Epoch 32/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5431 - acc: 0.9376\n",
      "Epoch 33/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5450 - acc: 0.9376\n",
      "Epoch 34/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5437 - acc: 0.9376\n",
      "Epoch 35/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5439 - acc: 0.9376\n",
      "Epoch 36/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5450 - acc: 0.9376\n",
      "Epoch 37/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5442 - acc: 0.9376\n",
      "Epoch 38/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5434 - acc: 0.9376\n",
      "Epoch 39/400\n",
      "2418/2418 [==============================] - 0s 63us/step - loss: 0.5441 - acc: 0.9376\n",
      "Epoch 40/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5433 - acc: 0.9376\n",
      "Epoch 41/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5439 - acc: 0.9376\n",
      "Epoch 42/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5445 - acc: 0.9376\n",
      "Epoch 43/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5434 - acc: 0.9376\n",
      "Epoch 44/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 45/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5432 - acc: 0.9376\n",
      "Epoch 46/400\n",
      "2418/2418 [==============================] - 0s 66us/step - loss: 0.5439 - acc: 0.9376\n",
      "Epoch 47/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5431 - acc: 0.9376\n",
      "Epoch 48/400\n",
      "2418/2418 [==============================] - 0s 63us/step - loss: 0.5435 - acc: 0.9376\n",
      "Epoch 49/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5443 - acc: 0.9376\n",
      "Epoch 50/400\n",
      "2418/2418 [==============================] - 0s 66us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 51/400\n",
      "2418/2418 [==============================] - 0s 62us/step - loss: 0.5436 - acc: 0.9376\n",
      "Epoch 52/400\n",
      "2418/2418 [==============================] - 0s 74us/step - loss: 0.5432 - acc: 0.9376\n",
      "Epoch 53/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5436 - acc: 0.9376\n",
      "Epoch 54/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 55/400\n",
      "2418/2418 [==============================] - 0s 65us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 56/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5435 - acc: 0.9376\n",
      "Epoch 57/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 58/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5441 - acc: 0.9376\n",
      "Epoch 59/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 60/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5435 - acc: 0.9376\n",
      "Epoch 61/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5430 - acc: 0.9376\n",
      "Epoch 62/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5425 - acc: 0.9376\n",
      "Epoch 63/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5431 - acc: 0.9376\n",
      "Epoch 64/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5411 - acc: 0.9376\n",
      "Epoch 65/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 66/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5430 - acc: 0.9376\n",
      "Epoch 67/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5433 - acc: 0.9376\n",
      "Epoch 68/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 69/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 70/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5444 - acc: 0.9376\n",
      "Epoch 71/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5430 - acc: 0.9376\n",
      "Epoch 72/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5439 - acc: 0.9376\n",
      "Epoch 73/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 74/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5416 - acc: 0.9376\n",
      "Epoch 75/400\n",
      "2418/2418 [==============================] - 0s 74us/step - loss: 0.5424 - acc: 0.9376\n",
      "Epoch 76/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 77/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 78/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5423 - acc: 0.9376\n",
      "Epoch 79/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5433 - acc: 0.9376\n",
      "Epoch 80/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5433 - acc: 0.9376\n",
      "Epoch 81/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5433 - acc: 0.9376\n",
      "Epoch 82/400\n",
      "2418/2418 [==============================] - 0s 66us/step - loss: 0.5416 - acc: 0.9376\n",
      "Epoch 83/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5438 - acc: 0.9376\n",
      "Epoch 84/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 85/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 86/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5413 - acc: 0.9376\n",
      "Epoch 87/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5434 - acc: 0.9376\n",
      "Epoch 88/400\n",
      "2418/2418 [==============================] - 0s 63us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 89/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 90/400\n",
      "2418/2418 [==============================] - 0s 75us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 91/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5411 - acc: 0.9376\n",
      "Epoch 92/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5443 - acc: 0.9376\n",
      "Epoch 93/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5423 - acc: 0.9376\n",
      "Epoch 94/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5414 - acc: 0.9376\n",
      "Epoch 95/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5431 - acc: 0.9376\n",
      "Epoch 96/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 97/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 98/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5432 - acc: 0.9376\n",
      "Epoch 99/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5431 - acc: 0.9376\n",
      "Epoch 100/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 101/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5429 - acc: 0.9376\n",
      "Epoch 102/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 103/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5432 - acc: 0.9376\n",
      "Epoch 104/400\n",
      "2418/2418 [==============================] - 0s 75us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 105/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 106/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5434 - acc: 0.9376\n",
      "Epoch 107/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5428 - acc: 0.9376\n",
      "Epoch 108/400\n",
      "2418/2418 [==============================] - 0s 66us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 109/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5420 - acc: 0.9376\n",
      "Epoch 110/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5435 - acc: 0.9376\n",
      "Epoch 111/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5424 - acc: 0.9376\n",
      "Epoch 112/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 113/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5410 - acc: 0.9376\n",
      "Epoch 114/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5423 - acc: 0.9376\n",
      "Epoch 115/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 116/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5432 - acc: 0.9376\n",
      "Epoch 117/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5413 - acc: 0.9376\n",
      "Epoch 118/400\n",
      "2418/2418 [==============================] - 0s 65us/step - loss: 0.5425 - acc: 0.9376\n",
      "Epoch 119/400\n",
      "2418/2418 [==============================] - 0s 76us/step - loss: 0.5417 - acc: 0.9376\n",
      "Epoch 120/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 121/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5412 - acc: 0.9376\n",
      "Epoch 122/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5433 - acc: 0.9376\n",
      "Epoch 123/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5437 - acc: 0.9376\n",
      "Epoch 124/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5423 - acc: 0.9376\n",
      "Epoch 125/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5423 - acc: 0.9376\n",
      "Epoch 126/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 127/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5413 - acc: 0.9376\n",
      "Epoch 128/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 129/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 130/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5420 - acc: 0.9376\n",
      "Epoch 131/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5417 - acc: 0.9376\n",
      "Epoch 132/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 133/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5417 - acc: 0.9376\n",
      "Epoch 134/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5415 - acc: 0.9376\n",
      "Epoch 135/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 136/400\n",
      "2418/2418 [==============================] - 0s 75us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 137/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5434 - acc: 0.9376\n",
      "Epoch 138/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5417 - acc: 0.9376\n",
      "Epoch 139/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5417 - acc: 0.9376\n",
      "Epoch 140/400\n",
      "2418/2418 [==============================] - 0s 76us/step - loss: 0.5420 - acc: 0.9376\n",
      "Epoch 141/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5415 - acc: 0.9376\n",
      "Epoch 142/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 143/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5424 - acc: 0.9376\n",
      "Epoch 144/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5425 - acc: 0.9376\n",
      "Epoch 145/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 146/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5403 - acc: 0.9376\n",
      "Epoch 147/400\n",
      "2418/2418 [==============================] - 0s 76us/step - loss: 0.5416 - acc: 0.9376\n",
      "Epoch 148/400\n",
      "2418/2418 [==============================] - 0s 64us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 149/400\n",
      "2418/2418 [==============================] - 0s 77us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 150/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5425 - acc: 0.9376\n",
      "Epoch 151/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 152/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5429 - acc: 0.9376\n",
      "Epoch 153/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 154/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5417 - acc: 0.9376\n",
      "Epoch 155/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5412 - acc: 0.9376\n",
      "Epoch 156/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 157/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5429 - acc: 0.9376\n",
      "Epoch 158/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5427 - acc: 0.9376\n",
      "Epoch 159/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 160/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 161/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5413 - acc: 0.9376\n",
      "Epoch 162/400\n",
      "2418/2418 [==============================] - 0s 64us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 163/400\n",
      "2418/2418 [==============================] - 0s 74us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 164/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5425 - acc: 0.9376\n",
      "Epoch 165/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5426 - acc: 0.9376\n",
      "Epoch 166/400\n",
      "2418/2418 [==============================] - 0s 66us/step - loss: 0.5416 - acc: 0.9376\n",
      "Epoch 167/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5425 - acc: 0.9376\n",
      "Epoch 168/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5424 - acc: 0.9376\n",
      "Epoch 169/400\n",
      "2418/2418 [==============================] - 0s 66us/step - loss: 0.5423 - acc: 0.9376\n",
      "Epoch 170/400\n",
      "2418/2418 [==============================] - 0s 67us/step - loss: 0.5421 - acc: 0.9376\n",
      "Epoch 171/400\n",
      "2418/2418 [==============================] - 0s 71us/step - loss: 0.5423 - acc: 0.9376\n",
      "Epoch 172/400\n",
      "2418/2418 [==============================] - 0s 64us/step - loss: 0.5424 - acc: 0.9376\n",
      "Epoch 173/400\n",
      "2418/2418 [==============================] - 0s 63us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 174/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5419 - acc: 0.9376\n",
      "Epoch 175/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5409 - acc: 0.9376\n",
      "Epoch 176/400\n",
      "2418/2418 [==============================] - 0s 73us/step - loss: 0.5424 - acc: 0.9376\n",
      "Epoch 177/400\n",
      "2418/2418 [==============================] - 0s 70us/step - loss: 0.5430 - acc: 0.9376\n",
      "Epoch 178/400\n",
      "2418/2418 [==============================] - 0s 68us/step - loss: 0.5415 - acc: 0.9376\n",
      "Epoch 179/400\n",
      "2418/2418 [==============================] - 0s 72us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 180/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5413 - acc: 0.9376\n",
      "Epoch 181/400\n",
      "2418/2418 [==============================] - 0s 69us/step - loss: 0.5412 - acc: 0.9376\n",
      "Epoch 182/400\n",
      "2418/2418 [==============================] - 0s 74us/step - loss: 0.5424 - acc: 0.9376\n",
      "Epoch 183/400\n",
      "2418/2418 [==============================] - 0s 79us/step - loss: 0.5422 - acc: 0.9376\n",
      "Epoch 184/400\n",
      "2418/2418 [==============================] - 0s 77us/step - loss: 0.5418 - acc: 0.9376\n",
      "Epoch 185/400\n",
      " 768/2418 [========>.....................] - ETA: 0s - loss: 0.5300 - acc: 0.9453"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-b319a6431aac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m                   \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sparse_categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                   metrics=['accuracy'])\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mcnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_comments\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1361\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1362\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1363\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1365\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    262\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2912\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeed_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_symbols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2914\u001b[1;33m     \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2915\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2916\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import regularizers\n",
    "cnn_model = tf.keras.Sequential([\n",
    "    keras.layers.Dense(64, input_shape=(20,)),\n",
    "    keras.layers.Dropout(rate=0.3,seed=1),\n",
    "    keras.layers.Dense(32,activation=tf.nn.softmax,kernel_regularizer=regularizers.l2(0.01),activity_regularizer=regularizers.l1(0.01)),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "    ])\n",
    "\n",
    "cnn_model.compile(optimizer=tf.train.AdamOptimizer(), \n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "cnn_model.fit(np.array(train_comments), train_labels, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1191/1191 [==============================] - 0s 220us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = cnn_model.evaluate(np.array(test_comments), test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.555272356251225, 0.9353484466834593)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loss, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
