# CS224D 

### lecture 1

自然语言处理的重要性

传统机器学习是人在制定真正的特征是什么，但是我们DP，我们需要电脑去学习特征。

对于深度学习，我们只是需要向其输入来自世界的原始信号，他是自己来定义特征的，你将得到多层的习得表征。

### lecture 2

one-hot 编码除了第x位，全是0

缺点：

1. 没有表示出任何词汇之间的内在关系概念，每个词语都是独立的

分布相似性：用上下文中的词来表示banking的含义

我们想要的是给每一个词一个密集的向量，让它可以预测目标单词所在文本的其他词汇。

word2vec：不同于独热算法，我们希望计算机能够提取出词的特征，最终得到一个低维的向量来描述一个词语的含义。![vector](vector.png)

两个算法：

1. skip-grams

   在每一个估算步都取一个词作为中心词汇，然后尝试去预测它一定范围内的上下文的词汇，得到一个上下问出现的概率

2. CBOW

   简单将就是完形填空

准备短期之内完成一个word2vec+PCA+SVM的一个小项目