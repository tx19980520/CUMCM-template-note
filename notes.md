# 数学建模学习

## 线性规划(Linear Programming)

运筹学的重要分支，作出最优决策

基本步骤：

1. 确定目标变量和决策变量
2. 根据决策变量与变量的函数关系确定目标函数
3. 根绝限制条件决定约束条件

使用线性规划的前提条件：

1. 比例性假定：一定要是线性的，别是二维的
2. 可加性假定：各个因素之间是相互独立的，从而可加
3. 连续性假定：决策变量是连续的
4. 确定性假定：不存在随机因素

有一份python的代码在Linear Programming，其条件为：



![Linear Programming](img\Linear Programming.png)

## 整数规划

直白一点讲就是离散的线性规划。

求解方法有5种：

- 分支定界法——可求纯或混合整数线性规划

分支定界是广度优先搜索的优化，在解空间树上搜索问题，不断利用限制条件进行剪枝，简单讲就是一个加条件的剪枝搜索。

- 割平面法——可求纯或混合整数线性规划

在做完一般线性规划后加入割平面条件进行修正。

- 隐枚举法——求解“0-1”整数规划

简单讲就是0-1背包问题和修塔问题

- 匈牙利法——解决指派问题

解决让n个人做n件事的问题，我们仍选择使用SciPy. Optimize中现成的算法进行解决，如果想看具体的算法操作请阅读https://blog.csdn.net/kevinjqy/article/details/54584114 和https://www.cnblogs.com/chenyg32/p/3293247.html

然后为了解决实际代码操作简便的问题，我们选择了使用python 的PuLP这个第三方库，他可以很简单的解决整数线性规划和混合线性规划。代码详见int programming

## 凸规划

## 二次规划

## 罚函数

## 斯坦纳树

最小生成树是最小斯坦纳树的一种特殊情况。

最小斯坦纳树允许在给定点外增加额外的点，使得生成的最短网络开销最小

生成这个树的算法实质上式外层prim，内层spfa(dijstra)

这个地方我们主要使用的是python的networkx第三方库，专门用于做网络和图论分析的。

斯坦纳树的板子请主要看代码，我为了简便，直接把所有core相互之间的路径全算了一遍

## 最大流

简单的讲就是求源到汇的最大流量，我们使用反向边的算法就可以了，即在找到一条增广路之后，对该条路上加上你流量的相同大小的相反路，以便于后悔，最后当源没有出度为0或者汇入度为0的时候，就是该算法结束的时候。你可以选择使用BFS对有向图进行遍历，最终可以得到最大流以及图。

代码还是python实现的，非常的简易。

## 免疫算法

现目前觉得和遗传算法没有太大的区别

## 遗传算法

![GA](img\GA.png)

这个算法的基本思想就是适者生存，这个部分存在三种确定适者的方式——锦标赛，轮盘赌和精英政策，锦标赛，就是直接选出适应程度最好的前n个，轮盘赌则是将他们的适应程度化成概率，然后进行random数字进行确定留下的元素，这种算法的随机性更大，精英政策则是对于**把群体在进化过程中迄今出现的最好个体(称为精英个体elitist)不进行配对交叉而直接复制到下一代中。   这种选择操作又称为复制(copy)。** 

交叉是生成后代，简单的讲就是对编码的特定部分进行一些计算操作生成下一代，变异则是对编码的随机位数进行计算操作，这两个地方的参数可以好好调一调。

遗传算法的框架我们决定使用gaft的python框架——https://github.com/PytLab/gaft，其相关的代码

## 蚁群算法(ACO)

模拟蚂蚁寻找食物的信息素释放的原理，使得程序得以进化。信息素会随着蚂蚁的经过而浓度增加，也会随着信息素会随着时间的推移而逐渐挥发。

我们讲这种算法必须有随机的部分，不然很容易得到局部最优解，因而我们在更新完信息素之后，我们需要计算下次对于该item是使用确定的信息素来执行，还是随机执行。

比较详细的一个算法的代码见文件夹ACO

关于信息素增量，我们还有三种常见的模型

![ant_info](img\ant_info.png)

## 粒子群算法

试设想在D维空间中有一群鸟，他们在寻找食物，我们通过多次修改他们的速度和位置，最终得到局部最优解的方法就是粒子群算法。

![PSO](img\PSO.jpg)

关于更新的部分，我们着重要注意的是在速度的更新上，因为我们知道，速度决定了粒子下一次的位置，我们为了避免局部最优解，得到全局最优解（理论上），我们需要我们的速度既有一定的随机性，又有一定的确定性，则有了如下的公式：
$$
v[i] = w * v[i] + c1 * rand() * (pbest[i] - present[i]) + c2 * rand() * (gbest - present[i])    
$$
v[i]表示第i个粒子的速度，w为惯性常量，即延续之前速度的多少，c1，c2是学习参数，一般为2，pbest[i]表示的是第i个粒子的经验最优值，gbest是全局最优值，rand()是两个随机数。rand()体现随机性，w体现的确定性。

## 支持向量机

## K领近

这个算法的主要步骤如下：

1. 计算测试数据与各个训练数据之间的距离；
2. 按照距离的递增关系进行排序；
3. 选取距离最小的K个点；
4. 确定前K个点所在类别的出现频率；
5. 返回前K个点中出现频率最高的类别作为测试数据的预测分类。

这个里面比较重要的就是计算距离这个步骤，除去大家非常熟悉的欧氏距离，还有曼哈顿距离之类的可供大家选择，因此一定要选好距离计算公式是非常重要的。

“学习”的近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用。但缺点是“学习”的估计误差会增大，预测结果会对近邻的实例点非常敏感。如果近邻的实例点恰巧是噪声，预测就会出错。换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合。

​        如果选择较大的K值，就相当于用较大邻域中的训练实例进行预测。其优点是可以减少学习的估计误差。但缺点是学习的近似误差会增大。这时，与输入实例较远（不相似的）训练实例也会对预测起作用，使预测发生错误。K值的增大就意味着整体的模型变得简单。

KNN拿sk-learn也是十分容易上手，代码已经在KNN文件夹中

## 逻辑回归(logistic regression)

日常我们通过线性回归模型得到了
$$
z = w^{T}x + b
$$


但是我们最后要输出的时0或者1，则我们需要一个单调可微的函数来供我们使用，于实我们得出了**Sigmoid Function**
$$
y = \frac{1}{1 + e^{-z}}
$$

其中我们得讲到一个概念叫做cost function 或者叫loss function，中文称代价函数。代价函数时含有w的参数，主要是为了通过计算，描述真实情况与模型之间的差距。同一代价函数下，代价函数所得值越小，模型更加的精确。

我们知道一般的逻辑回归只支持二分类，而大多数问题都是多分类问题，因此我们需要将其进行扩展。

现如今我们能够用的多分类的方法有：

1. KNN
2. tensorflow的方法实现的逻辑回归（把最后一个全连接层搞成具体的分类个数就行）看下ML里面的代码，可以跑，具体为啥不想追究。
3. SVM实现

打比赛的时候如果是要做分类的套路，先直接上聚类大概看看有哪些标签，然后回过头来再用分类算法得到最终的分类结果

## 支持向量机

SVM(support vector machine)是指在特征空间上找到最佳分离超平面使得训练集的间隔最大。是用来解决二分类问题的有监督学习算法。

硬间隔支持向量机是非常强硬的实施各点到超平面的距离来进行区分，但是我们很有可能得到的是一个过拟合的超平面，我们可能对于间隔不需要那么强硬的限制，则出现软间隔支持向量机，我们需要设定一个模糊一点的边界（大意是这样，数学上是增加一个代价损失。

现实任务中原始的样本空间DD中很可能并不存在一个能正确划分两类样本的超平面。例如图4中所示的问题就无法找到一个超平面将两类样本进行很好的划分。 

对于这样的问题可以通过将样本从原始空间映射到特征空间使得样本在映射后的特征空间里线性可分。例如对图5做特征映射z=x2+y2z=x2+y2可得到如图6所示的样本分布，这样就很好进行线性划分了。 

那么这个特征映射就是我们的核函数，把一个样本空间弄到一个更高维的空间里面，然后在高维空间里面进行切割，之后再映射回低维空间。

![SVM overfitting](img\SVM overfitting.jpg)

上图就是过拟合的情况，其实C = 10的情况下得到的分类已经非常好了。

这个部分的具体实现我们用sk-learn进行实现。

关于如何绘制分类出来的图，我收藏了一份代码，之后可以进行调整。

https://blog.csdn.net/cymy001/article/details/78532141

这个里面有多种算法的sklearn实现。

另外我们在sklearn官网上找到了关于调整kernel函数使用SVM的一个样例代码

## 决策树

通过我们的训练数据构建一棵决策树，从而进行分类。

比较常用的决策树有ID3，C4.5和CART（Classification And Regression Tree），CART的分类效果一般优于其他决策树。下面介绍具体步骤。

  ID3: 由增熵（Entrophy）原理来决定某个节点做父节点，那个节点需要分裂。对于一组数据，熵越大说明分类结果越好。越是小型的决策树越优于大的决策树，尽管如此，也不总是生成最小的树型结构，而是一个启发式算法。

一个随机变量ξ有A1、A2、A3……共n个不同的结果，每个结果出现的概率是p1、p2、p3……，那么我们把ξ的不确定度定义为信息熵，参考上面物理学熵的定义，A1、A2、A3……可以理解为不同的微观状态，那么看起来信息熵应该是log n喽？不然，因为这个随机变量ξ一次只能取一个值而不是多个值，所以应该按概率把ξ劈开，劈成n份，每份的微观状态数分别是1/p1、1/p2、1/p3……，这样这n份的熵分别是log 1/p1、log 1/p2、log 1/p3……，再根据熵的可加性原理，得到整体随机变量ξ的信息熵是∑(p log 1/p)，即
$$
H(ξ) = -∑(p log p)
$$


我们的信息增益的计算公式如下：
$$
IG(Sample|Attribute) = H(Sample) -∑_{value(Attribute)}\frac{|Samle_{v}|}{Sample}*H(Samle_{v})
$$
Attribute是指具体的某个属性，H(Sample)是指的整个信息的信息熵，而后者求和是指在按照Attribute区分下的条件熵，我们将两者最差得到信息增益，我们在选择谁作父节点的时候，需要选择所有因素中信息增益最大的进行。之后就一直贪心进行下去。

C4.5是对ID3的一个改进算法，是为了

1. 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足，公式GainRatio(A)；
2. 在树构造过程中进行剪枝
3. 能够完成对连续属性的离散化处理；
4. 能够对不完整数据进行处理。

信息增益率的定义如下：
$$
GainRatio(S,A) = \frac{IG(S|A)}{SplitInfo(S,A)}
$$

$$
SplitInfo(S, A) = -∑_{i = 1}^{c}\frac{|S_{i}|}{S}log(\frac{|S_{i}|}{S})
$$
SplitInfo会随着分类越多越大，分类越不均匀越大，从而信息增益率越小。

则，我们选择的分裂应该是分类较少，分类较为均匀的属性。

此外C4.5使用了EBP剪枝算法

CART：以ID3为基础的优化分类树

分裂的评判标准为GINI值
$$
GINI = 1 -∑P_{i}^{2}
$$
分裂的目的是为了让节点更纯，而我们的GINI值体现的是节点的不纯度，GINI值越大，节点越不纯，因此整个树的分裂就是为了减小GINI值。

最后我们得到Gain值
$$
Gain =∑p_i * GINI_i
$$
我们选择特征A的标准是Gini值的越小越好。

我们的决策树代码用sklearn实现以及其专用的可视化软件。

## 集成学习一觑

集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务。简单的想法就是生成多个个体学习器，个体学习器通常是由一个现有的学习算法从训练数据产生。这其中的学习器可以是同质的即，全是决策树，或者是异质的，例如又有决策树，又有神经网络。最终集成学习通过将多个学习器进行结合，可获得比单一学习器显著优越的泛化性能。

首先第一点，集成学习因为良好的泛化，则既提高了学习结果的上限，也拉低了学习结果的下限。例如集成学习的结果通过投票法来产生，“少数服从多数”，“真理往往掌握在少数人手中”这两种情况都有可能发生。

因此要想获得好的集成个体学习器应“好而不同”，要有一定的“准确性”，学习器之间要有一定的差异性。

### Bagging 算法(Bootstrap AGGregatING)

通过选取并放回的方式，从样本中采样出T个含m个训练样本的采样集，然后再基于每个采样集训练处一个基学习器，再将这所有的基学习器整合。

### Boosting 算法

先从出事训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，是的先前基学习做错的样本在后续受到更多的关注，一直生成N个基学习器，最终将这N个基学习器进行加权整合。

通过加法模型将弱分类器进行线性组合，比如AdaBoost通过加权多数表决的方式，即增大错误率小的分类器的权值，同时减小错误率较大的分类器的权值。

而提升树通过拟合残差的方式逐步减小残差，将每一步生成的模型叠加得到最终模型。

## 随机森林(Random Forest)

随机森林是在Bagging上进行扩展的一个变体。RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。曾经传统的决策树是首先选择其中一个最优属性，而在RF中，对基决策树的每个节点，先从该节点的属性集合中随机选择一个包含K个属性的子集，然后再从这个子集中选择一个最优属性用于划分，一般情况下k = logd

随机森林的具体实现代码仍旧使用sklearn

## 朴素贝叶斯

整个算法的基础就是贝叶斯公式，另一个部分则为朴素的意思，因为我们涉及到下面这个公式的成立
$$
P(XYZ|W) = P(X|W) + P(Y|W) + P(Z|W)
$$
这个公式成立的本质是要求XYZ这三个变量相互独立，所以这也是朴素贝叶斯名称的由来。

XYZ就是某个事物的特征，W相当于训练的label，之后便是非常简单的从原始数据中寻找到（甚至不需要，对n个特征初始化一个n*n的二维矩阵attribute，然后attribute\[i\]\[j\]记录的就是在第i个特征存在的情况下发生第j个事件的条件概率）

至于高斯朴素贝叶斯和伯努利朴素贝叶斯，只是上述计算单个P(X|W)的公式不一样了，不是简单的在原始数据中进行统计了，你主要要先看看自己的训练数据集如何再作判断。

关于多项式模型和伯努利模型，前者处理的是单词，后者主要处理文档。

多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。

后序可能做文本分析可能用就贝叶斯了。





# 聚类

聚类就是对大量未知标注的数据集，按照数据内部存在的数据特征将数据集划分为多个不同的类别，使类别内的数据比较相似，类别之间的数据相似度比较大；属于无监督学习。

聚类算法的重点是计算样本之间的相似度，有时候也称为样本间的距离。

相似度和距离是非常重的重要的指标，你可以有多种距离可供选择和组合。

## K-Means算法与变种

传统K-Means算法的步骤如下：

1. 从数据集D中随机选择k个样本作为初始的k个质心。
2. 对剩余点，进行对k个质心进行距离的计算，最终选择距离最短的进行归类。
3. 重新计算得到连续的质心，再找到离散质心。
4. 重复2，3过程知道迭代轮次达到，或质心没有移动。

这个算法不好的地方在于，我必须要指定k。且初始中心的这一步对于k-means算法非常的敏感。

变种：K-Means++算法

中心思想为初始聚类中心之间的相互距离要尽可能的远，但仍旧需要进行随机取样

1. 首先随机抽取一个点
2. 计算剩余点到该点最近聚类中心的距离
3. 利用轮盘赌的方式抽取新的聚类中心，抽到的概率与距离成正比
4. 最终在通过这k个初始的聚类中心来运行标准的k-means算法。

我们选择sk-learn实现K-Means

这个地方我们还要提到一个问题，就是关于高纬度的空间里面我们怎么做到使用k-means算法。

## MDS算法

非常传统的降维方法，以距离为基准，将高维坐标中的投影点投影到低维坐标中

这种对相似性矩阵的处理可以推广到一般情况，从而实现数据的压缩。简单的讲，譬如我们可以获知高维数据点的距离分布，它们的绝对位置对我们而言意义并不大，我们所关注的是点与点之间的距离关系，那么就可以通过MDS方法将高维点映射到二维空间，同时很好的保持了其距离关系。通过这样一个等距映射，我们就可以将数据量大幅减少，下面我们给出一个从三维空间向二维空间通过MDS方法进行等距映射的例子。 

我们有这么一个距离矩阵，我们通过这个矩阵计算出点的相对位置矩阵X，使得通过X反过来计算距离矩阵与原距离矩阵D差距最小。所以这是一个最优化问题。 

反正这真的是我很想要的一个算法，虽然我不会矩阵分解。

## SOM聚类

SOM的目标是用低维（通常是二维或三维）目标空间的点来表示高维空间中的所有点，尽可能地保持点间的距离和邻近关系（拓扑关系）。 

**结构：**

SOM为层次型结构。典型结构是：输入层加竞争层

输入层：接收外界信息，将输入模式向竞争层传递，起“观察”作用

竞争层：负责对输入模式进行“分析比较”，寻找规律并归类。

 优点：它将相邻关系强加在簇质心上，所以，互为邻居的簇之间比非邻居的簇之间更相关。这种联系有利于聚类结果的解释和可视化。

缺点：（1）用户必选选择参数、邻域函数、网格类型和质心个数

​            （2）一个SOM簇通常并不对应单个自然簇、可能有自然簇的合并和分裂。

​            （3）缺乏具体的目标函数

​            （4）SOM不保证收敛，尽管实际中它通常收敛



## Silhouette Coefficient系数

轮廓系数（Silhouette Coefficient），是聚类效果好坏的一种评价方式。最早由 Peter J. Rousseeuw 在 1986 提出。它结合内聚度和分离度两种因素。可以用来在相同原始数据的基础上用来评价不同算法、或者算法不同运行方式对聚类结果所产生的影响。 

1. 计算样本i到同簇其他样本的平均距离ai。ai 越小，说明样本i越应该被聚类到该簇。将ai 称为样本i的**簇内不相似度**。**簇C中所有样本的a i 均值称为簇C的簇不相似度。**

2. 计算样本i到其他某簇Cj 的所有样本的平均距离bij，称为样本i与簇Cj 的不相似度。定义为样本i的**簇间不相似度**：bi =min{bi1, bi2, ..., bik}**bi越大，说明样本i越不属于其他簇。**

3. 根据样本i的簇内不相似度a i 和簇间不相似度b i ，定义样本i的**轮廓系数**：

4. 判断：

   si接近1，则说明样本i聚类合理；

   si接近-1，则说明样本i更应该分类到另外的簇；

​      若si 近似为0，则说明样本i在两个簇的边界上。

我们可以通过这个系数的最大值，找到较为合适的k值

## 层次聚类(Hierarchical Clustering)

层次聚类就是一层一层的进行聚类，可以由上向下把大的类别（cluster）分割，叫作分裂法；也可以由下向上对小的类别进行聚合，叫作凝聚法；但是一般用的比较多的是由下向上的凝聚方法。本文会对分裂法略作简介和举个例子说明，重点介绍凝聚法，并且附上代码。 

### 分裂法

分裂法指的是初始时将所有的样本归为一个类簇，然后依据某种准则进行逐渐的分裂，直到达到某种条件或者达到设定的分类数目。

### 凝聚法

凝聚法指的是初始时将每个样本点当做一个类簇，所以原始类簇的大小等于样本点的个数，然后依据某种准则合并这些初始的类簇，直到达到某种条件或者达到设定的分类数目。



## 元胞自动机(CA)

是一时间和空间都离散的动力系统。散布在规则格网 (Lattice Grid)中的每一元胞(Cell)取有限的离散状态，遵循同样的作用规则，依据确定的局部规则作同步更新。大量元胞通过简单的相互作用而构成动态系统的演化。 

https://www.cnblogs.com/PaoYu/p/3196087.html

大概率不这么用

## 模特卡罗模拟

是以概率和统计的理论、方法为基础的一种数值计算方法，将所求解的问题同一定的概率模型相联系，用计算机实现统计模拟或抽样，以获得问题的近似解，故又称随机抽样法或统计试验法。 

对于涉及不可解析函数或概率分布的模拟及计算，蒙特卡洛方法是个有效的方法。 

蒙特卡罗需要先对假设某个事件服从什么概率，之后对另一个事件进行分析

例如我们的厂商生产食物，食物过了今天就会过期，厂里提供出两种方案进行设计产量，一种是按照昨天的生产量来生产，另一种是按照前天和昨天的生产量取平均来生产。

我们之后就可以靠蒙特卡罗模拟来实行整个过程n天，最后我们可以比较两种方法产生的效益。

## 马尔科夫

马尔柯夫预测以俄国数学家A.A.Markov名字命名，是利用状态之间转移概率矩阵预测事件发生的状态及其发展变化趋势，也是一种时**随间序列分析法**。 

状态是指某一事件在某个时刻（或时期）出现的某种结果。事件的发展，从一种状态转变为另一种状态，称为状态转移。在事件的发展过程中，若每次状态的转移都仅与前一时刻的状态有关，而与过去的状态无关，或者说状态转移过程是无后效性的，则这样的状态转移过程就称为马尔柯夫过程。 

状态转移概率矩阵。在事件发展变化的过程中，从某一种状态出发，下以时刻转移到其他状态的可能性，称为状态转移概率，只用统计特性描述随机过程的状态转移概率。若事物有n中状态，则从一种状态开始相应就有n个状态转移概率 。

满足下列两个假设的随机过程：

1. t+1时刻系统的状态概率分布只与t时刻有关
2. 从t时刻到t+1时刻的状态转移与t无关。

一个马尔科夫链模型可以表示为(S, P, Q)

1. S是系统所有可能的状态所组成的飞空状态集
2. P是状态转移矩阵，即Pij表示系统从i状态转移到j状态的概率
3. Q是系统初始的概率分布

## 随机游走

我们以随机游走求取一个函数的极大值为例进行说明。

1. 初始化得到n维向量x，初始化步长step，指定迭代次数N，指定迭代器k= 0，指定精度e
2. 当k  < N时，随机生成一个(-1, 1)之间的n为向量u，与xk = x+step*u
3. 如果找到一个比初始好的点，则k置为1，将x1变为x，若并未找到，则k +=1，之后进入第二步
4. 若连续N次找不到更优解，则认为，最优解就在当前最优解的中心，此时如果step小于e，则结束算法，否则我们的step =/ 2，k = 1。回到第二步

## PCA

PCA的思想是将n维特征映射到k维空间中，k维特征是全新的正交特征，并非从原空间中抽取的。

我们认为数据本来是在低维的一个空间，是存在噪声才导致维度增加。

这个线性空间被称为主⼦空间（principal subspace），使得投影数据的⽅差被最⼤化（Hotelling, 1933），即最大方差理论。 



我们需要的是用较少的变量来表示较大的变异

在信号处理中认为信号具有较大的方差，噪声有较小的方差，信噪比就是信号与噪声的方差比，越大越好。因此我们认为，最好的kk维特征是将n维样本点变换为k维后，每一维上的样本方差都尽可能的大。 



BN的优化，归一化处理，使数据分布更加集中。



## GM 灰色模型

白色系统是指系统内部特征是完全已知的；黑色系统是指系统内部信息完全未知的；而灰色系统是介于白色系统和黑色系统之间的一种系统，灰色系统其内部一部分信息已知，另一部分信息未知或不确定。 



## 时序模型与递归神经网络（RNN）

基于RNN的语言模型利用RNN本身输入是序列的特点，在隐含层神经元之上加了全连接层、Softmax层，得到输出词的概率分布。 

