# 数学建模学习

## 线性规划(Linear Programming)

运筹学的重要分支，作出最优决策

基本步骤：

1. 确定目标变量和决策变量
2. 根据决策变量与变量的函数关系确定目标函数
3. 根绝限制条件决定约束条件

使用线性规划的前提条件：

1. 比例性假定：一定要是线性的，别是二维的
2. 可加性假定：各个因素之间是相互独立的，从而可加
3. 连续性假定：决策变量是连续的
4. 确定性假定：不存在随机因素

有一份python的代码在Linear Programming，其条件为：



![Linear Programming](img\Linear Programming.png)

## 整数规划

直白一点讲就是离散的线性规划。

求解方法有5种：

- 分支定界法——可求纯或混合整数线性规划

分支定界是广度优先搜索的优化，在解空间树上搜索问题，不断利用限制条件进行剪枝，简单讲就是一个加条件的剪枝搜索。

- 割平面法——可求纯或混合整数线性规划

在做完一般线性规划后加入割平面条件进行修正。

- 隐枚举法——求解“0-1”整数规划

简单讲就是0-1背包问题和修塔问题

- 匈牙利法——解决指派问题

解决让n个人做n件事的问题，我们仍选择使用SciPy. Optimize中现成的算法进行解决，如果想看具体的算法操作请阅读https://blog.csdn.net/kevinjqy/article/details/54584114 和https://www.cnblogs.com/chenyg32/p/3293247.html

然后为了解决实际代码操作简便的问题，我们选择了使用python 的PuLP这个第三方库，他可以很简单的解决整数线性规划和混合线性规划。代码详见int programming

## 凸规划

## 二次规划

## 罚函数

## 斯坦纳树

最小生成树是最小斯坦纳树的一种特殊情况。

最小斯坦纳树允许在给定点外增加额外的点，使得生成的最短网络开销最小

生成这个树的算法实质上式外层prim，内层spfa(dijstra)

这个地方我们主要使用的是python的networkx第三方库，专门用于做网络和图论分析的。

斯坦纳树的板子请主要看代码，我为了简便，直接把所有core相互之间的路径全算了一遍

## 最大流

简单的讲就是求源到汇的最大流量，我们使用反向边的算法就可以了，即在找到一条增广路之后，对该条路上加上你流量的相同大小的相反路，以便于后悔，最后当源没有出度为0或者汇入度为0的时候，就是该算法结束的时候。你可以选择使用BFS对有向图进行遍历，最终可以得到最大流以及图。

代码还是python实现的，非常的简易。

## 免疫算法

现目前觉得和遗传算法没有太大的区别

## 遗传算法

![GA](img\GA.png)

这个算法的基本思想就是适者生存，这个部分存在三种确定适者的方式——锦标赛，轮盘赌和精英政策，锦标赛，就是直接选出适应程度最好的前n个，轮盘赌则是将他们的适应程度化成概率，然后进行random数字进行确定留下的元素，这种算法的随机性更大，精英政策则是对于**把群体在进化过程中迄今出现的最好个体(称为精英个体elitist)不进行配对交叉而直接复制到下一代中。   这种选择操作又称为复制(copy)。** 

交叉是生成后代，简单的讲就是对编码的特定部分进行一些计算操作生成下一代，变异则是对编码的随机位数进行计算操作，这两个地方的参数可以好好调一调。

遗传算法的框架我们决定使用gaft的python框架——https://github.com/PytLab/gaft，其相关的代码

## 蚁群算法(ACO)

模拟蚂蚁寻找食物的信息素释放的原理，使得程序得以进化。信息素会随着蚂蚁的经过而浓度增加，也会随着信息素会随着时间的推移而逐渐挥发。

我们讲这种算法必须有随机的部分，不然很容易得到局部最优解，因而我们在更新完信息素之后，我们需要计算下次对于该item是使用确定的信息素来执行，还是随机执行。

比较详细的一个算法的代码见文件夹ACO

关于信息素增量，我们还有三种常见的模型

![ant_info](img\ant_info.png)

## 粒子群算法

试设想在D维空间中有一群鸟，他们在寻找食物，我们通过多次修改他们的速度和位置，最终得到局部最优解的方法就是粒子群算法。

![PSO](img\PSO.jpg)

关于更新的部分，我们着重要注意的是在速度的更新上，因为我们知道，速度决定了粒子下一次的位置，我们为了避免局部最优解，得到全局最优解（理论上），我们需要我们的速度既有一定的随机性，又有一定的确定性，则有了如下的公式：
$$
v[i] = w * v[i] + c1 * rand() * (pbest[i] - present[i]) + c2 * rand() * (gbest - present[i])    
$$
v[i]表示第i个粒子的速度，w为惯性常量，即延续之前速度的多少，c1，c2是学习参数，一般为2，pbest[i]表示的是第i个粒子的经验最优值，gbest是全局最优值，rand()是两个随机数。rand()体现随机性，w体现的确定性。

## 支持向量机

## K领近

这个算法的主要步骤如下：

1. 计算测试数据与各个训练数据之间的距离；
2. 按照距离的递增关系进行排序；
3. 选取距离最小的K个点；
4. 确定前K个点所在类别的出现频率；
5. 返回前K个点中出现频率最高的类别作为测试数据的预测分类。

这个里面比较重要的就是计算距离这个步骤，除去大家非常熟悉的欧氏距离，还有曼哈顿距离之类的可供大家选择，因此一定要选好距离计算公式是非常重要的。

“学习”的近似误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用。但缺点是“学习”的估计误差会增大，预测结果会对近邻的实例点非常敏感。如果近邻的实例点恰巧是噪声，预测就会出错。换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合。

​        如果选择较大的K值，就相当于用较大邻域中的训练实例进行预测。其优点是可以减少学习的估计误差。但缺点是学习的近似误差会增大。这时，与输入实例较远（不相似的）训练实例也会对预测起作用，使预测发生错误。K值的增大就意味着整体的模型变得简单。

KNN拿sk-learn也是十分容易上手，代码已经在KNN文件夹中

## 逻辑回归(logistic regression)

日常我们通过线性回归模型得到了
$$
z = w^{T}x + b
$$


但是我们最后要输出的时0或者1，则我们需要一个单调可微的函数来供我们使用，于实我们得出了**Sigmoid Function**
$$
y = \frac{1}{1 + e^{-z}}
$$

其中我们得讲到一个概念叫做cost function 或者叫loss function，中文称代价函数。代价函数时含有w的参数，主要是为了通过计算，描述真实情况与模型之间的差距。同一代价函数下，代价函数所得值越小，模型更加的精确。

我们知道一般的逻辑回归只支持二分类，而大多数问题都是多分类问题，因此我们需要将其进行扩展。

现如今我们能够用的多分类的方法有：

1. KNN
2. tensorflow的方法实现的逻辑回归（把最后一个全连接层搞成具体的分类个数就行）看下ML里面的代码，可以跑，具体为啥不想追究。
3. SVM实现

打比赛的时候如果是要做分类的套路，先直接上聚类大概看看有哪些标签，然后回过头来再用分类算法得到最终的分类结果

## 支持向量机

SVM(support vector machine)是指在特征空间上找到最佳分离超平面使得训练集的间隔最大。是用来解决二分类问题的有监督学习算法。

硬间隔支持向量机是非常强硬的实施各点到超平面的距离来进行区分，但是我们很有可能得到的是一个过拟合的超平面，我们可能对于间隔不需要那么强硬的限制，则出现软间隔支持向量机，我们需要设定一个模糊一点的边界（大意是这样，数学上是增加一个代价损失。

现实任务中原始的样本空间DD中很可能并不存在一个能正确划分两类样本的超平面。例如图4中所示的问题就无法找到一个超平面将两类样本进行很好的划分。 

对于这样的问题可以通过将样本从原始空间映射到特征空间使得样本在映射后的特征空间里线性可分。例如对图5做特征映射z=x2+y2z=x2+y2可得到如图6所示的样本分布，这样就很好进行线性划分了。 

那么这个特征映射就是我们的核函数，把一个样本空间弄到一个更高维的空间里面，然后在高维空间里面进行切割，之后再映射回低维空间。

![SVM overfitting](img\SVM overfitting.jpg)

上图就是过拟合的情况，其实C = 10的情况下得到的分类已经非常好了。

这个部分的具体实现我们用sk-learn进行实现。

关于如何绘制分类出来的图，我收藏了一份代码，之后可以进行调整。

https://blog.csdn.net/cymy001/article/details/78532141

这个里面有多种算法的sklearn实现。

另外我们在sklearn官网上找到了关于调整kernel函数使用SVM的一个样例代码

## 决策树

通过我们的训练数据构建一棵决策树，从而进行分类。

比较常用的决策树有ID3，C4.5和CART（Classification And Regression Tree），CART的分类效果一般优于其他决策树。下面介绍具体步骤。

  ID3: 由增熵（Entrophy）原理来决定某个节点做父节点，那个节点需要分裂。对于一组数据，熵越大说明分类结果越好。越是小型的决策树越优于大的决策树，尽管如此，也不总是生成最小的树型结构，而是一个启发式算法。

一个随机变量ξ有A1、A2、A3……共n个不同的结果，每个结果出现的概率是p1、p2、p3……，那么我们把ξ的不确定度定义为信息熵，参考上面物理学熵的定义，A1、A2、A3……可以理解为不同的微观状态，那么看起来信息熵应该是log n喽？不然，因为这个随机变量ξ一次只能取一个值而不是多个值，所以应该按概率把ξ劈开，劈成n份，每份的微观状态数分别是1/p1、1/p2、1/p3……，这样这n份的熵分别是log 1/p1、log 1/p2、log 1/p3……，再根据熵的可加性原理，得到整体随机变量ξ的信息熵是∑(p log 1/p)，即
$$
H(ξ) = -∑(p log p)
$$


我们的信息增益的计算公式如下：
$$
IG(Sample|Attribute) = H(Sample) -∑_{value(Attribute)}\frac{|Samle_{v}|}{Sample}*H(Samle_{v})
$$
Attribute是指具体的某个属性，H(Sample)是指的整个信息的信息熵，而后者求和是指在按照Attribute区分下的条件熵，我们将两者最差得到信息增益，我们在选择谁作父节点的时候，需要选择所有因素中信息增益最大的进行。之后就一直贪心进行下去。

C4.5是对ID3的一个改进算法，是为了

1. 用信息增益率来选择属性，克服了用信息增益选择属性时偏向选择取值多的属性的不足，公式GainRatio(A)；
2. 在树构造过程中进行剪枝
3. 能够完成对连续属性的离散化处理；
4. 能够对不完整数据进行处理。

信息增益率的定义如下：
$$
GainRatio(S,A) = \frac{IG(S|A)}{SplitInfo(S,A)}
$$

$$
SplitInfo(S, A) = -∑_{i = 1}^{c}\frac{|S_{i}|}{S}log(\frac{|S_{i}|}{S})
$$
SplitInfo会随着分类越多越大，分类越不均匀越大，从而信息增益率越小。

则，我们选择的分裂应该是分类较少，分类较为均匀的属性。

此外C4.5使用了EBP剪枝算法

CART：以ID3为基础的优化分类树

分裂的评判标准为GINI值
$$
GINI = 1 -∑P_{i}^{2}
$$
分裂的目的是为了让节点更纯，而我们的GINI值体现的是节点的不纯度，GINI值越大，节点越不纯，因此整个树的分裂就是为了减小GINI值。

最后我们得到Gain值
$$
Gain =∑p_i * GINI_i
$$
我们的决策树代码用sklearn实现以及其专用的可视化软件。

## 集成学习一觑

集成学习（ensemble learning）通过构建并结合多个学习器来完成学习任务。简单的想法就是生成多个个体学习器，个体学习器通常是由一个现有的学习算法从训练数据产生。这其中的学习器可以是同质的即，全是决策树，或者是异质的，例如又有决策树，又有神经网络。最终集成学习通过将多个学习器进行结合，可获得比单一学习器显著优越的泛化性能。

首先第一点，集成学习因为良好的泛化，则既提高了学习结果的上限，也拉低了学习结果的下限。例如集成学习的结果通过投票法来产生，“少数服从多数”，“真理往往掌握在少数人手中”这两种情况都有可能发生。

因此要想获得好的集成个体学习器应“好而不同”，要有一定的“准确性”，学习器之间要有一定的差异性。

### Bagging 算法(Bootstrap AGGregatING)

通过选取并放回的方式，从样本中采样出T个含m个训练样本的采样集，然后再基于每个采样集训练处一个基学习器，再将这所有的基学习器整合。

### Boosting 算法

先从出事训练集训练出一个基学习器，再根据基学习器的表现对训练样本分布进行调整，是的先前基学习做错的样本在后续受到更多的关注，一直生成N个基学习器，最终将这N个基学习器进行加权整合。

通过加法模型将弱分类器进行线性组合，比如AdaBoost通过加权多数表决的方式，即增大错误率小的分类器的权值，同时减小错误率较大的分类器的权值。

而提升树通过拟合残差的方式逐步减小残差，将每一步生成的模型叠加得到最终模型。

## 随机森林(Random Forest)

随机森林是在Bagging上进行扩展的一个变体。RF在以决策树为基学习器构建Bagging集成的基础上，进一步在决策树的训练过程中引入了随机属性选择。曾经传统的决策树是首先选择其中一个最优属性，而在RF中，对基决策树的每个节点，先从该节点的属性集合中随机选择一个包含K个属性的子集，然后再从这个子集中选择一个最优属性用于划分，一般情况下k = logd

随机森林的具体实现代码仍旧使用sklearn

## 朴素贝叶斯

整个算法的基础就是贝叶斯公式，另一个部分则为朴素的意思，因为我们涉及到下面这个公式的成立
$$
P(XYZ|W) = P(X|W) + P(Y|W) + P(Z|W)
$$
这个公式成立的本质是要求XYZ这三个变量相互独立，所以这也是朴素贝叶斯名称的由来。

XYZ就是某个事物的特征，W相当于训练的label，之后便是非常简单的从原始数据中寻找到（甚至不需要，对n个特征初始化一个n*n的二维矩阵attribute，然后attribute\[i\]\[j\]记录的就是在第i个特征存在的情况下发证第j个事件的条件概率）

至于高斯朴素贝叶斯和伯努利朴素贝叶斯，只是上述计算单个P(X|W)的公式不一样了，不是简单的在原始数据中进行统计了，你主要要先看看自己的训练数据集如何再作判断。

关于多项式模型和伯努利模型，前者处理的是单词，后者主要处理文档。

多项式模型以单词为粒度，伯努利模型以文件为粒度，因此二者的先验概率和类条件概率的计算方法都不同。计算后验概率时，对于一个文档d，多项式模型中，只有在d中出现过的单词，才会参与后验概率计算，伯努利模型中，没有在d中出现，但是在全局单词表中出现的单词，也会参与计算，不过是作为“反方”参与的。

后序可能做文本分析可能用就贝叶斯了。











